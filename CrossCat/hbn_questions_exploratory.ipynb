{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis with BayesDB\n",
    "\n",
    "Adapted by Jon Clucas of the [Child Mind Institute](https://www.childmind.org) from a notebook that was prepared for The DARPA PPAML PI meeting, July 2017 by [Feras Saad](http://fsaad.mit.edu) of the MIT Probabilistic Computing Project (Probcomp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Jupyter environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load the `jupyter_probcomp.magics` library, which provides BayesDB hooks for data exploration, plotting, querying, and analysis through this Jupyter notebook environment. The second cell allows plots from matplotlib and javascript to be shown inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_probcomp.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%vizgpm inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a BayesDB `.bdb` file on disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next use the `%bayesdb` magic to create a `.bdb` file on disk named `hbnq.bdb`. This file will store all the data and models created in this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f resources/hbnq.bdb\n",
    "%bayesdb resources/hbnq.bdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting data from a `.csv` file into a BayesDB table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hbnq dataset is stored in the csv file `data/Train_Set.csv`. Each column of the csv file is a variable, and each row is a record. We use the `CREATE TABLE` BQL query, with the pathname of the csv file, to convert the csv data into a database table named `hbnq_t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql DROP TABLE \"hbnq_t\"\n",
    "%bql CREATE TABLE \"hbnq_t\" FROM 'data/Train_Set.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all datasets have missing values, and special tokens such as `NaN` or `NA` indicating a particular cell is missing. In the HBNQ data, empty strings are used. To tell BayesDB to treat empty strings as SQL `NULL` we use the `.nullify` command, followed by the name of the table and the string `''` which represents missing data. Over 30,000 cells have been converted to `NULL`, illustrating that the data is quite sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql .nullify hbnq_t ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running basic queries on the table using BQL and SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the HBNQ dataset has been loaded into at table, and missing values converted to `NULL`, we can run standard SQL queries to explore the contents of the data. For example, we can select the first 5 records. Observe that each row in the table is a particular country, and each column is a macreconomic variable. Scroll through the names in the header of the table to get a sense of the marcoeconomic variables in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql SELECT * FROM \"hbnq_t\" LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find the total number of records (i.e. countries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql SELECT COUNT(*) FROM \"hbnq_t\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling the columns in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full `hbnq_t` table contains over 300 columns. In this notebook, our exploratory analysis will be based on a random subsample of 100 columns. To create the subsample, we use the `.subsample_columns` magic. The `--keep` flag accepts a list of column names which should be kept. We will keep the `Name` column, since it is the identifier for each record. The `--seed` flag specifies the random seed to create the subsample, which will ensure our analyses are reproducible. Finally, `hbnq_t` is the original table, `hbnq_t_subsample` is the name of the new table, and 100 is the number of columns to downsample to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql DROP TABLE IF EXISTS hbnq_t_subsample\n",
    "%bql .subsample_columns --seed=8 --keep=Dx --keep=EID hbnq_t hbnq_t_subsample 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a BayesDB population for the HBNQ data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notion of a \"population\" is a central concept in BayesDB. For a standard database table, such as `hbnq_t`, each column is associated with a [data type](https://sqlite.org/datatype3.html), which in sqlite3 are `TEXT`, `REAL`, `INTEGER`, and `BLOB`. For a BayesDB population, each variable is associated with a _statistical data type_. These statistical types, such as `NOMINAL`, `NUMERICAL`, `MAGNITUDE`, and `COUNTS`, specify the set of values and default probability distributions used for building probabilistic models of the data in the population. In this tutorial, we will use the `NUMERICAL` and `NOMINAL` statistical data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `GUESS SCHEMA FOR <table>` command from the Metamodeling Language (MML) in BayesDB to guess the statistical data types of variables in the table. The guesses use heuristics based on the contents in the cells. The `num_distinct` column shows the number of unique values for that variable, and the `reason` column explains which heuristic was used to make the guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mml GUESS SCHEMA FOR \"hbnq_t_subsample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The `country` column has been identified as the `key`, since it is a unique identifer for each row. Many of the variables have been also correctly guessed  as `NUMERICAL`. A few variables have been incorrectly guessesd as `NOMINAL`, probably due to the sparsity in the dataset (the reason is that there are only a few distinct values for that variable in the table).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the HBNQ variables and their statistical datatypes, we use MML to create a population for the `hbnq_t_subsample` table. We will call the population `hbnq`. The population schema uses the statistical types guessed by BayesDB (from the previous cell) for all variables, except for a set of manual overrides for the incorrect guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%mml\n",
    "CREATE POPULATION \"hbnq\" FOR \"hbnq_t_subsample\" WITH SCHEMA (\n",
    "    -- Use the guesses from the previous cell for all variables.\n",
    "    GUESS STATTYPES FOR (*);\n",
    "\n",
    "    -- Manually override incorrectly guessed statistical types.\n",
    "    -- MODEL\n",
    "    --    \"poverty headcount ratio at rural poverty line (% of rural population)\",\n",
    "    --    \"stunt 0-4 unicef who\",\n",
    "    --    \"drought killed\",\n",
    "    --    \"youth (15-24) literacy rate (%). total\",\n",
    "    --    \"oda % gni\",\n",
    "    --    \"air accidents killed\", \"earthquake affected\" \n",
    "    --AS NUMERICAL;\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing joint distributions of data in the population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equipped with the statistical data types of variables in the population, we can now use the plotting features of BayesDB to produce scatter plots and heatmaps for the marginal and (pairwise) joint distributions of variables of interest. The `.interactive_pairplot` command requires a flag `--population=<pop>` for the population name, followed a BQL query. It generates pairplots of the data in all pairs of columns yielded by the query . Below, we have selected five variables to pairplot (recall that we have 100 variables in total). What features do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bql\n",
    ".interactive_pairplot --population=hbnq \n",
    "SELECT\n",
    "    \"Dx\",\n",
    "    \"SWAN_09\",\n",
    "    \"SRS_12\",\n",
    "    \"SWAN_Total\",\n",
    "    \"SRS_COM_T.x\"\n",
    "FROM hbnq_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to create more pairplots of the data before moving on to the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an analysis schema for the population using CrossCat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created the `gapminder` population, the next step is to analyze the data by building probabilistic models which explain the data generating process. Probabilistic data analyses in BayesDB are specified using an `ANALYSIS SCHEMA`. The default model discovery engine in BayesDB is Cross-Categorization [(Crosscat)](http://jmlr.org/papers/v17/11-392.html). CrossCat is a Bayesian factorial mixture model which learns a full joint distribution over all variables in the population, using a divide-and-conquer approach. We will explore CrossCat more in this notebook.\n",
    "\n",
    "For now we use MML to declare the an analysis schema named `hbnq_crosscat` for the `hbnq` population. Note that that we have left the schema in `crosscat()` empty, which will apply the built-in defaults. Specifying custom analysis schemas is the subject of another tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mml CREATE ANALYSIS SCHEMA \"hbnq_crosscat\" FOR \"hbnq\" WITH BASELINE crosscat();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After specifying the `hbnq_crosscat` analysis schema, we now need to initialize `ANALYSES` for the schema. We can think of an `ANALYSIS SCHEMA` as specifying a hypothesis space of explanations for the data generating process for the population, and each `ANALYSIS` is a candidate hypothesis. We start by creating only 1 analysis, which is initialized __randomly__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mml INITIALIZE 1 ANALYSIS FOR \"hbnq_crosscat\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a CrossCat hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, CrossCat learns the full joint distribution of all variables in the population using divide-and-conquer:\n",
    "\n",
    "- First, CrossCat partitions the variables into a set of _views_; all the variables in a particular view are modeled jointly, and two variables in different views are independent of one another.\n",
    "- Second, within each view, CrossCat clusters the rows using a non-parametric mixture model.\n",
    "\n",
    "The name Cross-Categorization is derived from this two-step process: first categorize the variables into views, and then categorize the rows into clusters within each view of variables. It is important to note that two different views A and B are likely to induce different clusterings of the rows.\n",
    "\n",
    "To get a sense of CrossCat's hypothesis space, we can render the hypothesis specified by a particular analysis using the `.render_crosscat [options] <analysis_schema> <analysis_identifier>` plotting command. The `--subsample=50` option says to only show a subsample of 50 rows in the rendering (even though `gampinder_crosscat` is modeling all countries in the `gapminder` population); `--rowlabels=country` specifies which column in the table to use to label the rows. Finally `gapminder_crosscat 0` means to render the first (and only) analysis in the `gapminder_crosscat` anlaysis schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%mml .render_crosscat \\\n",
    "    --subsample=50 --rowlabels=EID --xticklabelsize=small --yticklabelsize=xx-small --progress=True --width=64 \\\n",
    "    hbnq_crosscat 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To view a full-size image of the rendering, either double click the image, or right-click and select \"Open image in new tab.\"__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we emphasize that the CrossCat hypothesis shown above is __randomly__ initialized based on the two-step clustering process we have described. Each block of columns shows a view of dependent variables. The clusters within a view are demarcated using solid pink lines. Each row is a country from `gapminder`. The color of a cell shows the magnitude of the data (normalized between 0 and 1, where light indicates lower values and dark indices higher values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using BQL to query CrossCat models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the CrossCat rendering, each pair of variables is either in the same view (and therefore probably dependent), or in different views (and therefore independent). We can query the detected probable dependencies between all pairs of variables using the `DEPENDENCE PROBABILITY` estimator in BQL. The next query produces a heatmap of all pairs of dependencies. In the heatmap below, each row and column is a variable, and the color of a cell is a value between 0 and 1 (lighter is nearer to 0, and darker is nearer to 1) indicating the amount of evidence for a predictive relationship or dependency between these two variables. Since we have initialized only 1 CrossCat analysis, each cell is exactly either 0 (if those variables are in different views), or 1 (variables are in the same view). Confirm that the blocks shown in the heatmap match up with the blocks of variables from the rendering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql .interactive_heatmap ESTIMATE DEPENDENCE PROBABILITY FROM PAIRWISE VARIABLES OF hbnq;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving Crosscat hypotheses using MML `ANALYZE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have initialized a CrossCat hypothesis and investigated its state, it is time to improve our initial guess by exploring the hypothesis space to find hypotheses that better explain the data. In particular, our single CrossCat analysis has both spurious dependencies as well as independencies between variables which we would expect to be depedenct (study the heatmap and rendering, can you locate some of these pairs?).\n",
    "\n",
    "We can improve the CrossCat hypothesis by using the MML `ANALYZE` command, which takes the name of an analysis schema, an amount of iterations or seconds, and optional arguments. It then searches for improved hypotheses. Here, the `OPTIMIZED` keyword indicates to BayesDB to use a faster inference engine --- we generally recommend using this flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mml ANALYZE \"hbnq_crosscat\" FOR 200 ITERATIONS WAIT (OPTIMIZED);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the new CrossCat after running 200 steps of analysis. Study the dependent variables. Can you identify a \"theme\" or \"category\" which summarizes each view? For example, the fourth view from the left has variables \"residential electricty consumption\", \"electricity generation per person\", and \"hydro production\", indicating that this may view might summarize energy variables. Which dependencies or independencies are still spurious?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mml .render_crosscat \\\n",
    "    --subsample=50 --rowlabels=EIN --xticklabelsize=small --yticklabelsize=xx-small --progress=True --width=64 \\\n",
    "    hbnq_crosscat 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again visualize the probability there exists a dependence, between all pairs of variables, using BQL. How does this heatmap differ qualitatively from the dependence probability heatmap we plotted prior to running `ANALYZE`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql .interactive_heatmap ESTIMATE DEPENDENCE PROBABILITY FROM PAIRWISE VARIABLES OF hbnq;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in addition to learning a clustering of variables, CrossCat additionally learns a clustering of the rows within each view. These clusters are separated using pink lines in the CrossCat rendering. We can use the `SIMILARITY IN THE CONTEXT OF <variable>` query in BQL to study CrossCat's row partition in the view of `<variable>`.\n",
    "\n",
    "In the heatmap below, each row and column is a participant, and the value of a cell (between 0 and 1) indicates the probability that those two countries are relevant for formulating predictions about each other. Do these clusters of participants make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql .interactive_heatmap --label0=rowid --label1=EID --table=hbnq_t \\\n",
    "    ESTIMATE SIMILARITY IN THE CONTEXT OF  \"Dx\" FROM PAIRWISE hbnq;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing more CrossCat analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we used `INITIALIZE 1 ANALYSIS FOR gapminder_crosscat` to create a single analysis. As a result, all of our heatmaps (such as a variable dependencies and row similarities) had \"sharp\" values (either 1 or 0). Since CrossCat has a very large hypothesis space, we can significantly improve modeling by creating an ensemble of analyses, where each analysis searches the hypothesis space for hypotheses that fit the data well. All queries in BQL will then become weighted averages of the query results from each individual analysis in the ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `%multiprocess on` magic activates multiprocessing BayesDB which allow us to initialize, analyze and run queries on analyses using multiple cores on the host machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%multiprocess on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following MML command ensures the `gapminder_crosscat` analysis schema will have a total of 32 analyses in the ensemble (recall that we already initialized 1 analysis, so the 31 new analyses will be added)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mml INITIALIZE 32 MODELS IF NOT EXISTS FOR \"hbnq_crosscat\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we run 1 minute of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mml ANALYZE \"hbnq_crosscat\" FOR 150 ITERATIONS WAIT (OPTIMIZED);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let use produce some renderings of the analyses (here we choose 5, 7 and 15). Where is there consensus among these three analyses? Where do they disagree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%mml .render_crosscat \\\n",
    "    --subsample=50 --rowlabels=EID --xticklabelsize=small --yticklabelsize=x-small hbnq_crosscat 5\n",
    "%mml .render_crosscat \\\n",
    "    --subsample=50 --rowlabels=EID --xticklabelsize=small --yticklabelsize=x-small hbnq_crosscat 7\n",
    "%mml .render_crosscat \\\n",
    "    --subsample=50 --rowlabels=EID --xticklabelsize=small --yticklabelsize=x-small hbnq_crosscat 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring probable dependencies between variables and comparing CrossCat dependence probability to linear (Pearson R) correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, all BQL queries are aggregated across the 32 analyses in the ensemble. We will create a table named `dependencies` which contains the pairwise `DEPENDENCE PROBABILITY` values between the Gapminder variables. The value of a cell (between 0 and 1) is the fraction of analyses in the ensemble where those two variables are detected to be probably dependent (i.e. they are in the same view)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bql\n",
    "CREATE TABLE dependencies AS\n",
    "ESTIMATE\n",
    "    DEPENDENCE PROBABILITY AS \"depprob\"\n",
    "FROM PAIRWISE VARIABLES OF hbnq;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are five random rows from the `dependencies` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql SELECT * FROM \"dependencies\" ORDER BY RANDOM() LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again summarize the `dependencies` table using a heatmap. Study this dependence heatmap, and compare it to the heatmap produced when there was only 1 analysis. Which common-sense dependencies were missed by the single model, but identified by the ensemble as probably dependent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql .interactive_heatmap SELECT name0, name1, depprob FROM dependencies;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare dependence probabilities from CrossCat to linear (Pearson r) correlation values, a very common technique for finding predictive relationships. We can compute the Pearson R (and its p-value) in BayesDB using the `CORRELATION` and `CORRELATION PVALUE` queries. The following cell creates a table named `correlations`, which contains the R and p-value for all pairs of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bql\n",
    "CREATE TABLE \"correlations\" AS\n",
    "ESTIMATE\n",
    "    CORRELATION AS \"correlation\",\n",
    "    CORRELATION PVALUE AS \"pvalue\"\n",
    "FROM PAIRWISE VARIABLES OF \"hbnq\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are five random rows from the `correlations` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql SELECT * FROM \"correlations\" ORDER BY RANDOM() LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Emphasis__: There is a signficiant difference between `DEPENDENCE PROBABILITY`, `CORRELATION`, and `CORRELATION PVALUE`. We outline these differences below, which will help us make comparisons between predictive relationships detected by CrossCat versus Pearson correlation.\n",
    "\n",
    "- `DEPENDENCE PROBABILITY`: Returns a value between [0,1] indicating the __probability there exists__ a predictive relationship (statistical dependence) between two variables.\n",
    "\n",
    "- `CORRELATION`: Returns a value between [0,1] indicating the __strength__ of the linear relationsip between two variables, where 0 means no linear correlation, and 1 means perfect linear correlation.\n",
    "\n",
    "- `CORRELATION PVALUE`: Returns a value between (0, 1) indicating the tail probability of the observed correlation value between two variables, under the null hypothesis that the two variables have zero correlation.\n",
    "\n",
    "Based on these distinctions, there is no immediate way to numerically compare `DEPENDENCE PROBABILITY` with `CORRELATION/CORRELATION PVALUE`. However, it is possible to compare the inferences about predictive relationships that each method gives rise to, which we do in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first produce a heatmap of the raw correlation values. The following query shows the raw correlation values (between 0 and 1) for all pairs of variables where the p-value is less than 0.01 (note that we are not accounting for multiple-testing using e.g. Bonferroni correction). Pairs of variables where the p-value exceeds 0.01 (and thus the null hypothesis of independence cannot be rejected) are shown in gray. The sparsity of the data makes it difficult to draw inferences about many variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql .interactive_heatmap SELECT name0, name1, \"correlation\" FROM \"correlations\" WHERE \"pvalue\" < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the heatmap, and compare it to the heatmap from `DEPENDENCE PROBABILITY`. The patterns of dependence relationships differ significantly, how?\n",
    "\n",
    "We can use BQL to find variables which CrossCat believes are probably dependent, but correlation believes are independent (either the null hypothesis of independence cannot be rejected, or the correlation value is significant and near zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    \"name0\",\n",
    "    \"name1\",\n",
    "    \"dependencies\".\"depprob\",\n",
    "    \"correlations\".\"correlation\",\n",
    "    \"correlations\".\"pvalue\"\n",
    "FROM\n",
    "    \"dependencies\"\n",
    "    JOIN \"correlations\"\n",
    "    USING (\"name0\", \"name1\")\n",
    "WHERE\n",
    "    -- CrossCat: probability dependent.\n",
    "    \"dependencies\".\"depprob\" > 0.85\n",
    "    AND (\n",
    "    -- Correlation: cannot reject null hypothesis of independence.\n",
    "    \"correlations\".\"pvalue\" > 0.05\n",
    "    OR (\n",
    "    -- Correlation: linear relationship is significant and near zero.\n",
    "    \"correlations\".\"pvalue\" < 0.05 AND \"correlations\".\"correlation\" < 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to determine why the dependence probability of `female 5-9 years (%)` with `female 20-39 (%)` is very high according to CrossCat (greater than 0.90), but the linear correlation coefficient is near 0 (and the null hypothesis of independence cannot be rejected anyway).\n",
    "\n",
    "The next cell produces a scatter plot of these two variables. We notice that they are indeed dependent, although the pattern is quite strange; it has a piecewise relationship where `female 20-39` is linearly correlated with `female 5-9 years` with an upward trend for values of `female 5-9 years` less than 10, but with a downward trend for values of `female 5-9 years` greater than 10. What are some possible explanations for the piecewise relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql .interactive_scatter SELECT \"srs_45\", \"csc_12p\" FROM \"hbnq_t_subsample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This finding illustrates that CrossCat analyses are able to detect non-linear and heteroskedastic predictive relationships between variables, which match our common-sense intuitions. A similar pattern can be seen in the scatter plot between `female 20-39 years` and `children per woman`, shown in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql .interactive_scatter SELECT \"swan_total\", \"cbcl_wd_t\" FROM \"hbnq_t_subsample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use also BQL to find variables which CrossCat believes are probably independent, but correlation believes are dependent (a statistically significant non-zero correlation value, where we are using an R cutoff of 0.15). The following query shows a list of such variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    \"name0\",\n",
    "    \"name1\",\n",
    "    \"dependencies\".\"depprob\",\n",
    "    \"correlations\".\"correlation\",\n",
    "    \"correlations\".\"pvalue\"\n",
    "FROM\n",
    "    \"dependencies\"\n",
    "    JOIN \"correlations\"\n",
    "    USING (\"name0\", \"name1\")\n",
    "WHERE\n",
    "    -- CrossCat: high uncertainty about dependence probability.\n",
    "    \"dependencies\".\"depprob\" < 0.05\n",
    "    AND (\n",
    "    -- Correlation: statistically significant dependence.\n",
    "    \"correlations\".\"pvalue\" < 0.05 AND \"correlations\".\"correlation\" > 0.15)\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us genreate scatter plots of some these variables, such as `armed forces personnel` versus `epidemic affected`, and `working hours per week` versus `air accidents killed`, which linear correlations spuriously detects are dependent, but CrossCat correctly identifies as probably independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql .interactive_scatter SELECT \"armed forces personnel\", \"epidemic affected\" FROM \"gapminder_t_subsample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql .interactive_scatter SELECT \"working hours per week\", \"air accidents killed\" FROM \"gapminder_t_subsample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that linear correlation is deceived into detecting a dependency due to a single outlier in both cases. As a non-parametric mixture model, CrossCat is more robust to outliers and irregular patterns in the data, especially when there is insufficient evidence in the data to result in CrossCat reporting probable dependencies (as is the case in the two scatter plots, with only one data point deviating from the zero-dependence trend).\n",
    "\n",
    "Bonferroni correction for multiple testing would perhaps render the p-values of these correlations as statistically insignificant. However, Bonferroni is also highly conservative, and will cause many common-sense relationships to be insigificant as well under linear correlation. These design trade-offs are very common in drawing inferences from frequentist methods such Pearson R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some next questions you might explore include:\n",
    "\n",
    "- For which variables do CrossCat and linear correation agree about dependencies?\n",
    "- Which pairs of variables have the most uncertainty about their dependence probability (a dependence probability value of 0.5 represents the most uncertainy, or a light green color)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding countries which are predictively relevant to one another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have explored dependencies between variables found by CrossCat, we next move to finding which countries in the Gapminder population are relevant to formulating predictions about one another. Recall from the visualizations of CrossCat that, within each _view_ of dependent variables, CrossCat learns a clustering of the countries. These country clusterings will typically differ based on the view. Also recall that different CrossCat analyses in the ensemble (we have 32 in total) will find different clusterings for both variables and rows, which we aggregate over using BQL queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the BQL `PREDICTIVE RELEVANCE` query to find rows which are relevant for formulating predictions about one another, in the \"context\" of a variable in the population. The context of a variable is the set of variables in the CrossCat view for the context variable. A full description of this query can be found in \n",
    "\n",
    "> _Probabilistic Search for Structured Data via Probabilistic Programming and Nonparametric Bayes_. Saad, F.; Casarsa, L.; and Mansinghka, V. arXiv preprint, arXiv:1704.01087. 2017. [PDF](https://arxiv.org/abs/1704.01087).\n",
    "\n",
    "In this tutorial, we will focus only on the simplest queries for exploratory analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of queries are more efficient to run without multiprocessing, so we will disable it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%multiprocess off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first query finds the top 15 countries which are relevant to formulating predictions about the `life expectancy at birth` (and variables in its context) for the `United States`. We find that the result set contains rich nations with Western-style democracies and similar standards of living to that of the US. Notice that the set of relevant countries in this case is not based on geographic features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bql\n",
    ".interactive_bar \n",
    "ESTIMATE\n",
    "    \"country\",\n",
    "    PREDICTIVE RELEVANCE\n",
    "        TO EXISTING ROWS (country='United States')\n",
    "        IN THE CONTEXT OF \"life expectancy at birth\"\n",
    "        AS \"Relevance to United States (Life Expectancy)\"\n",
    "FROM gapminder\n",
    "ORDER BY \"Relevance to United States (Life Expectancy)\"\n",
    "DESC LIMIT 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find the list of countries which are relevant to the `United States` in the context of `armed forces personnel`. The result set is now much different, where almost no countries are predictively relevant. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bql\n",
    ".interactive_bar \n",
    "ESTIMATE\n",
    "    \"country\",\n",
    "    PREDICTIVE RELEVANCE\n",
    "        TO EXISTING ROWS (country='United States')\n",
    "        IN THE CONTEXT OF \"armed forces personnel\"\n",
    "        AS \"Relevance to United States (Military Personnel)\"\n",
    "FROM gapminder\n",
    "ORDER BY \"Relevance to United States (Military Personnel)\" DESC LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us sort the countires by their `armed forces personnel`. We notice that there are other countries whose `armed forces personnel` is on the same scale as the US. But none of these countries are typically considered to share the same macroeconomic or political characteristics as the United States, so are not detected as predictively relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bql SELECT \"country\", \"armed forces personnel\" FROM gapminder_t ORDER BY \"armed forces personnel\" DESC limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now find the top 15 countries which are relevant to formulating predictions about the `life expectancy at birth` (and variables in its context) for the Ukraine. Notice that these countries are all Eastern European nations and former Soviet states. In this case, CrossCat has recovered relevances which are related to both geography as well as shared macroeconomic and political characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bql\n",
    ".interactive_bar \n",
    "ESTIMATE\n",
    "    \"country\",\n",
    "    PREDICTIVE RELEVANCE\n",
    "        TO EXISTING ROWS (country='Ukraine')\n",
    "        IN THE CONTEXT OF \"life expectancy at birth\"\n",
    "        AS \"Relevance to Ukraine (Life Expectancy)\"\n",
    "FROM gapminder\n",
    "ORDER BY \"Relevance to Ukraine (Life Expectancy)\" DESC LIMIT 15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
